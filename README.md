### *Цель работы*:
Цель работы - создание/обучение модели восстанавливающей пропущенные пробелы.
Например : "Этохорошаяработа,наверно" --> "Это хорошая работа, наверно"

### *Анализ тестовых данных и сбор датасета*:
После анализа тестового файла, на котором будет проводиться оценка модели, было выявлено, что строки, в большинстве своём, либо из объявлений, либо из песен.
Я собран датасет с похожей тематикой.
Датасет состоит из двух частей:

* 1 часть - это фрагменты русской литературы. Датасет был взят с сайта https://www.kaggle.com/datasets/artalmaz31/complex-russian-dataset.

Был взят файл **books-B.txt**

* 2 часть - это объявления Авито. Был взят файл **train_part_0002.snappy.parquet** с сайта https://www.kaggle.com/datasets/antonoof/avito-data

Далее 1 часть  была обработана и разделена по пробелам и каждые 10 слов стали  новым элементом в итоговом датасете.
Пример:
    ['В смысле они улетели? с неимоверным удивлением спрашиваю у Арти,',
     'все еще не в силах поверить в это, слишком уж',
     'неожиданно и вообще странно как-то. В прямом, флот вышел в',
     'звездной системе недалеко от нас, предполагаю для корректировки курса, они',
     'так делают при прыжках на очень большие расстояния, а потом']

 
Из второй части в новый датасет попали первые 12 слов каждого объявления
Всего датасет состоял из **623797** строк.

### *Обучение модели*:
Была дообучена (full fine tuning) модель **cointegrated/rubert-tiny2**
Всего было 3 эпохи. Модель обучалась примерно час, 15 минут из которых, была лишь валидация модели (Поставил слишком частую валидацию)

